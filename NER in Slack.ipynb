{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f68ccd75",
   "metadata": {},
   "source": [
    "### Process for incorporation of named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701f153",
   "metadata": {},
   "source": [
    "We want recognition of:</br>\n",
    "<li>Email</li>\n",
    "<li>Phone numbers</li>\n",
    "<li>Dates</li>\n",
    "<li>Time</li>\n",
    "<li>Address</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c91e7d",
   "metadata": {},
   "source": [
    "To implement, we need to do the following steps:</br>\n",
    "<li>For each document inside the BM25 class, instantiate a regex_matches and a category dictionary</li>\n",
    "<li>Run regex for phone numbers and emails on each corpus and record the number of matches in regex_matches dictionary</li>\n",
    "<li>Record frequency of date, time and address named entities as determined by spaCy in the category dictionary.</li>\n",
    "<li>Update the frequency dictionary (for each individual word in each document) with the category dictionary for that document</li>\n",
    "<li>Nothing else should be changed, since our changes so far should've accounted for the counting of categories that the verbatim term frequency and inverse document frequency would've missed.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "556b5b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import math\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe430f",
   "metadata": {},
   "source": [
    "### Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33132c0",
   "metadata": {},
   "source": [
    "A US phone number has 10 digits, and may include hyphens or brackets. I remove all punctuation using regex, and find occurrences of suvh numbers by using a regular expression. \n",
    "An email needs to contain an '@' symbol, as well as a period after which a domain extension is specified.</br>\n",
    "Credit to <a href = 'https://www.geeksforgeeks.org/check-if-email-address-valid-or-not-in-python/'>GeekforGeeks</a> for guidance on finding emails from strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9ea7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_regex = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n",
    "phone_regex = re.compile(r'\\b([0-9]{3}-[0-9]{3}-[0-9]{4})\\b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7384d",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6bb7661",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'his phone number is 652-982-3987. Mine is 872-974-8342'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "feacf26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['652-982-3987', '872-974-8342']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(phone_regex, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1d66cc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fas@dfasd.edu', 'ihsfa@jdf.com']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(email_regex, 'email fas@dfasd.edu ihsfa@jdf.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ca8a3",
   "metadata": {},
   "source": [
    "### Incorporating in BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf8d2a",
   "metadata": {},
   "source": [
    "This is adapted from the rank_bm25 library; credit to <a href=\"https://github.com/dorianbrown/rank_bm25\">Dorian Brown</a>. Changes I made:<br>\n",
    "<li>Adding regular expressions to detect emails and phone numbers</li>\n",
    "<li>Resolving entities in the initialization of the BM25 class</li>\n",
    "<li>Constraining tokenizing by spaces inside the class</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44d07b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25:\n",
    "    def __init__(self, corpus, tokenizer=None):\n",
    "        self.corpus_size = len(corpus)\n",
    "        self.avgdl = 0\n",
    "        self.doc_freqs = []\n",
    "        self.idf = {}\n",
    "        self.doc_len = []\n",
    "        self.tokenizer = tokenizer\n",
    "        # compiling regular expressions\n",
    "        self.email_regex = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n",
    "        self.phone_regex = re.compile(r'\\b([0-9]{3}-[0-9]{3}-[0-9]{4})\\b')\n",
    "\n",
    "        if tokenizer:\n",
    "            corpus = self._tokenize_corpus(corpus)\n",
    "\n",
    "        nd = self._initialize(corpus)\n",
    "        self._calc_idf(nd)\n",
    "\n",
    "    def _initialize(self, corpus):\n",
    "        nd = {}  # word -> number of documents with word\n",
    "        num_doc = 0\n",
    "        for document in corpus:\n",
    "            self.doc_len.append(len(document))\n",
    "            num_doc += len(document)\n",
    "            # we apply spaCy's named entity recognition to the document\n",
    "            category = {}\n",
    "            doc = nlp(document)\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == 'GPE' or ent.label_ == 'LOC':\n",
    "                    if 'locations' not in category:\n",
    "                        category['locations'] = 0\n",
    "                    category['locations'] += 1\n",
    "                elif ent.label_ == 'DATE':\n",
    "                    if 'dates' not in category:\n",
    "                        category['dates'] = 0\n",
    "                    category['dates'] += 1\n",
    "                elif ent.label_ == 'TIME':\n",
    "                    if 'times' not in category:\n",
    "                        category['times'] = 0\n",
    "                    category['times'] += 1\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            # regular expressions to detect phone numbers and emails\n",
    "            regex_matches = {}\n",
    "            email_matches = re.findall(self.email_regex, document)\n",
    "            phone_matches = re.findall(self.phone_regex, document)\n",
    "            regex_matches['email'] = len(email_matches)\n",
    "            regex_matches['phone'] = len(phone_matches)\n",
    "            \n",
    "            # this is for verbatim matching with the query\n",
    "            frequencies = {}\n",
    "            # we tokenize the corpus\n",
    "            tokenized_corpus = document.split(\" \")\n",
    "            for word in tokenized_corpus:\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 0\n",
    "                frequencies[word] += 1\n",
    "            frequencies.update(category)\n",
    "            frequencies.update(regex_matches)\n",
    "            self.doc_freqs.append(frequencies)\n",
    "            \n",
    "            for word, freq in frequencies.items():\n",
    "                try:\n",
    "                    nd[word]+=1\n",
    "                except KeyError:\n",
    "                    nd[word] = 1\n",
    "\n",
    "        self.avgdl = num_doc / self.corpus_size\n",
    "        return nd\n",
    "\n",
    "    def _tokenize_corpus(self, corpus):\n",
    "        pool = Pool(cpu_count())\n",
    "        tokenized_corpus = pool.map(self.tokenizer, corpus)\n",
    "        return tokenized_corpus\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_batch_scores(self, query, doc_ids):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_top_n(self, query, documents, n=5):\n",
    "\n",
    "        assert self.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
    "\n",
    "        scores = self.get_scores(query)\n",
    "        top_n = np.argsort(scores)[::-1][:n]\n",
    "        return [documents[i] for i in top_n]\n",
    "\n",
    "\n",
    "class BM25Okapi(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, epsilon=0.25):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.epsilon = epsilon\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        \"\"\"\n",
    "        Calculates frequencies of terms in documents and in corpus.\n",
    "        This algorithm sets a floor on the idf values to eps * average_idf\n",
    "        \"\"\"\n",
    "        # collect idf sum to calculate an average idf for epsilon value\n",
    "        idf_sum = 0\n",
    "        # collect words with negative idf to set them a special epsilon value.\n",
    "        # idf can be negative if word is contained in more than half of documents\n",
    "        negative_idfs = []\n",
    "        for word, freq in nd.items():\n",
    "            idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
    "            self.idf[word] = idf\n",
    "            idf_sum += idf\n",
    "            if idf < 0:\n",
    "                negative_idfs.append(word)\n",
    "        self.average_idf = idf_sum / len(self.idf)\n",
    "\n",
    "        eps = self.epsilon * self.average_idf\n",
    "        for word in negative_idfs:\n",
    "            self.idf[word] = eps\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        \"\"\"\n",
    "        The ATIRE BM25 variant uses an idf function which uses a log(idf) score. To prevent negative idf scores,\n",
    "        this algorithm also adds a floor to the idf value of epsilon.\n",
    "        See [Trotman, A., X. Jia, M. Crane, Towards an Efficient and Effective Search Engine] for more info\n",
    "        :param query:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n",
    "                                               (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
    "        return score\n",
    "\n",
    "    def get_batch_scores(self, query, doc_ids):\n",
    "        \"\"\"\n",
    "        Calculate bm25 scores between query and subset of all docs\n",
    "        \"\"\"\n",
    "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
    "        score = np.zeros(len(doc_ids))\n",
    "        doc_len = np.array(self.doc_len)[doc_ids]\n",
    "        for q in query:\n",
    "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
    "            score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n",
    "                                               (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
    "        return score.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2449f1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.        0.        0.        0.1355042]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"Hello there good man!\",\n",
    "    \"It is quite windy in London\",\n",
    "    \"How is the weather today?\",\n",
    "    \"my email is ahfs@ndf.com\",\n",
    "    \"Please Contact : Traci Kantzas 203-292-5006 | Traci@greenfieldsource.com\"\n",
    "]\n",
    "\n",
    "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "bm25 = BM25Okapi(corpus)\n",
    "query = \"phone numbers\"\n",
    "tokenized_query = query.split(\" \")\n",
    "doc_scores = bm25.get_scores(tokenized_query)\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ffe7e1",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ffb3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dateutil\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8930911",
   "metadata": {},
   "source": [
    "The test data is the message history of the #jobs-and-internships channel in the I School of Information (obtained with permission from the IT team). It spans 2020-11-02 to 2021-12-15. I remove all fields outside of:<br>\n",
    "<li>'user', which is the Slack user ID</li>\n",
    "<li>'text', the message content</li>\n",
    "<li>'ts', the Unix timestamp</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a50180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = '2020-11-02'\n",
    "first_date = dateutil.parser.parse(first_date)\n",
    "df = pd.read_json(\"jobs-and-internships/2020-11-02.json\")\n",
    "df = df[['user', 'text', 'ts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe853ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(341): \n",
    "    first_date += datetime.timedelta(days=1)\n",
    "    try:\n",
    "        df_add = pd.read_json(\"jobs-and-internships/\" + str(first_date)[0:10] + '.json')\n",
    "        df_add = df_add[['user', 'text', 'ts']]\n",
    "        df = pd.concat([df, df_add], ignore_index = True)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11334a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1497, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6436d1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>U5N1K4YG0</td>\n",
       "      <td>&lt;@U01G53LLB42&gt;The recruiter from Cruise reache...</td>\n",
       "      <td>1.629753e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>U01DSD43ECF</td>\n",
       "      <td>&lt;@U01DSD43ECF&gt; has joined the channel</td>\n",
       "      <td>1.606238e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>U01FRBJM4SV</td>\n",
       "      <td>Here are internship positions at FB: &lt;https://...</td>\n",
       "      <td>1.628354e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UEV3JDG12</td>\n",
       "      <td>HI, Any one here who can help me with a referr...</td>\n",
       "      <td>1.604527e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>URRQ1E50S</td>\n",
       "      <td>Karen do you have specific contacts that could...</td>\n",
       "      <td>1.614629e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>U01CKHVJMH7</td>\n",
       "      <td>&lt;@U01CKHVJMH7&gt; has joined the channel</td>\n",
       "      <td>1.606268e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>U1UHKAMFD</td>\n",
       "      <td>you know, i never considered that before joini...</td>\n",
       "      <td>1.619020e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>U1UJVQ0G4</td>\n",
       "      <td>Another goodie: &lt;https://twitter.com/egoodman/...</td>\n",
       "      <td>1.632315e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>UEKS87R5K</td>\n",
       "      <td>This is a posting from the firm my wife used t...</td>\n",
       "      <td>1.608751e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>U0298P5SH40</td>\n",
       "      <td>I didn’t know McD Tech Labs existed! How excit...</td>\n",
       "      <td>1.628014e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user                                               text  \\\n",
       "1318    U5N1K4YG0  <@U01G53LLB42>The recruiter from Cruise reache...   \n",
       "78    U01DSD43ECF              <@U01DSD43ECF> has joined the channel   \n",
       "1247  U01FRBJM4SV  Here are internship positions at FB: <https://...   \n",
       "5       UEV3JDG12  HI, Any one here who can help me with a referr...   \n",
       "572     URRQ1E50S  Karen do you have specific contacts that could...   \n",
       "83    U01CKHVJMH7              <@U01CKHVJMH7> has joined the channel   \n",
       "882     U1UHKAMFD  you know, i never considered that before joini...   \n",
       "1428    U1UJVQ0G4  Another goodie: <https://twitter.com/egoodman/...   \n",
       "253     UEKS87R5K  This is a posting from the firm my wife used t...   \n",
       "1226  U0298P5SH40  I didn’t know McD Tech Labs existed! How excit...   \n",
       "\n",
       "                ts  \n",
       "1318  1.629753e+09  \n",
       "78    1.606238e+09  \n",
       "1247  1.628354e+09  \n",
       "5     1.604527e+09  \n",
       "572   1.614629e+09  \n",
       "83    1.606268e+09  \n",
       "882   1.619020e+09  \n",
       "1428  1.632315e+09  \n",
       "253   1.608751e+09  \n",
       "1226  1.628014e+09  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51684246",
   "metadata": {},
   "source": [
    "I save this as a csv file for testing. This is attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b525ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Slack_test_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4353be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = list(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc4ca06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test_corpus = [doc.split(\" \") for doc in test_corpus]\n",
    "bm25 = BM25Okapi(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a23fb05",
   "metadata": {},
   "source": [
    "#### \"phone numbers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2866825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"phone numbers\"\n",
    "tokenized_query = query.split(\" \")\n",
    "doc_scores = bm25.get_scores(tokenized_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94653497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fworkforcenow.adp.com%2Fmascsr%2Fdefault%2Fmdf%2Frecruitment%2Frecruitment.html%3Fcid%3D35e6c783-42c6-456d-a2d7-5348ce39bd8d%26ccId%3D19000101_000001%26lang%3Den_US&amp;data=04%7C01%7Cjfogel%40mediquant.com%7Cc6e50d0fdfbd4592a3a508d8ea254ccb%7Cee99115b93684a8ba65e601d3afd6236%7C1%7C0%7C637516793210062319%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=bHTIeZzD6wqcclhCoZggD5Mnprv%2BeFoZx6kTKQKe0XM%3D&amp;reserved=0|MediQuant> out of Ohio is looking for Data Engineers, Data Modelers, Clinical Business Systems Analysts, and more. Contact <mailto:lindsay_ludlow@mediquant.com|Lindsay Ludlow> if interested (<tel:9102325259|910-232-5259>).\n",
      "Result:\n",
      "Annual <https://skydeckrecuiting2020.eventbrite.com/|MEng + SkyDeck Startup Recruiting Event> This is not another Zoom event! Please join us on the interactive platform, Remo, for our annual <https://skydeckrecuiting2020.eventbrite.com/|MEng + SkyDeck Startup Recruiting Event> on Wednesday, December 9th from 2-4:30pm. *You do not need to attend the entire event.*\n",
      "\n",
      "Over 20 companies are looking to connect with the MEng community to collaborate on projects and fill internships and full-time roles! <https://docs.google.com/spreadsheets/d/1HjgxnR6D154DREW4SUS-ibUWL2Nt99ih7iiS43a02Ao/edit?usp=sharing|Prepare ahead of the event and research attending companies here.>\n",
      "\n",
      "<https://skydeck.berkeley.edu/|Berkeley SkyDeck> is UC Berkeley's largest startup accelerator - since 2012 they have put 300+ startups through its doors. SkyDeck helps some of Berkeley's top founders build their companies, focusing on deep technology that can change the world. Areas of interest include Medtech, Robotics, Space, AI, VR/AR, Software &amp; more!\n",
      "\n",
      "*<https://skydeckrecuiting2020.eventbrite.com/|Register> to receive the event link on the interactive platform Remo!*\n",
      "\n",
      "*Test run -* If you would like to test the platform ahead of the event; please join us the day before on 12/8 from 12:00 pm-1:00 pm: <https://live.remo.co/e/test-run-fall-2020-skydeck-meng->\n",
      "\n",
      "*More info about the event and platform -* The event will begin with brief opening remarks from SkyDeck's Executive Director, Caroline Winnett, followed by a 1 minute pitch from each startup.\n",
      "1. *Upon entering the event you will be first be placed at a random table, and you can see the company name labeled to each table;*\n",
      "2. If you would like to move to a different table, simply *double click* on the one you would like to go to;\n",
      "3. You will need to join on laptop/desktop, mobile doesn't work well;\n",
      "4. *Remo runs entirely on your web browser, we recommend to use a recent version of Chrome or Firefox* for a stable experience;\n",
      "5. Lounge areas are available for you to take a break;\n",
      "6. Fung Institute and SkyDeck info tables will be staffed if you have any questions;\n",
      "7. You can join Remo via your Google account; \n",
      "8. Below is a sneak peak of the event map of <https://docs.google.com/spreadsheets/d/1HjgxnR6D154DREW4SUS-ibUWL2Nt99ih7iiS43a02Ao/edit?mc_cid=809e63f2d4&amp;mc_eid=c0aa1445d4#gid=1562337353|attending companies>;\n",
      "9. <https://skydeckrecuiting2020.eventbrite.com/|Register> ahead of the event so we know how many people to expect;\n",
      "10. Have fun!\n",
      "Floor 1\n",
      "\n",
      "Floor 2\n",
      "\n",
      "\n",
      "```\n",
      "__________```\n",
      "Julie McShane\n",
      "Director, Career Development &amp; Alumni Relations\n",
      "Fung Institute For Engineering Leadership\n",
      "University of California, Berkeley - College of Engineering\n",
      "Room 222 Shires Hall, 2451 Ridge Road, Berkeley, CA 94709\n",
      "```510-642-6402  |  Appointment Calendar | Campus Wellness Resources```\n",
      "\n",
      "Result:\n",
      "*Research Associate – Center for Effective Global Action (CEGA)*\n",
      "* *\n",
      "The Center for Effective Global Action (CEGA) seeks a full-time Research Associate to support the Center’s Faculty Director.\n",
      "*About CEGA*\n",
      "CEGA is a West Coast hub for research on global development, with a network of 120+ academic researchers extending across the University of California, Stanford University, and the University of Washington. Our faculty affiliates design and test solutions for the problems of poverty, generating actionable evidence for policy-makers in low- and middle-income countries. Through careful matchmaking, competitive grant-making, and research dissemination activities, CEGA ensures that the scientific evidence we produce improves the lives of people living in poverty.\n",
      "\n",
      "CEGA is committed to diversity, equity, and inclusion – please read our values statement <https://cega.berkeley.edu/values/|here>.\n",
      "*Position Details*\n",
      "CEGA seeks a motivated Research Associate to support the Center’s Faculty Director, Edward Miguel. The Research Associate will coordinate field research activities for rigorous evaluations of social and economic programs in Africa, with a focus on the Kenya Life Panel Survey project. S/he will also provide critical administrative support including coordinating the Working Group in African Political Economy (WGAPE), budgeting/contracting, events management, and outreach/communications, while contributing to Center-wide process improvements and performance management. The Research Associate will work closely with Professor Miguel, who will provide mentorship and supervision, and will collaborate with other CEGA staff as needed. While this position is based in Berkeley, there will be periodic field work assignments in Kenya.\n",
      "This is a challenging opportunity for an early-career professional who is passionate about global development and social science research; has a strong desire to expand and deepen skills in research administration, project planning, and partnership development; is a successful self-learner; and is energized to contribute to the long-term success of a dynamic organization.\n",
      "*Responsibilities include but are not limited to:*\n",
      "*Research Assistance (75%)*\n",
      "• Assist with data cleaning, data analysis, and replication activities (STATA, R).\n",
      "• Conduct background research in conjunction with field activities.\n",
      "• Design, refine, and pilot research questionnaires.\n",
      "• Support data collection and data entry to ensure data quality.\n",
      "• Liaise with field staff in Kenya on a variety of topics, including data quality, developing human subject protocols, grants management, survey questionnaire development and coding, etc.\n",
      "• Assist in the preparation of documents and presentations for grant proposals, donor reporting, and dissemination activities.\n",
      "• Manage a team of 3-5 graduate and undergraduate students per semester including hiring, onboarding, creating assignments, training and supervising work.\n",
      "*Administrative Assistance (25%)*\n",
      "\n",
      "Result:\n",
      "Hi Julian,  do you happen to know what kind of experience level they are looking for?\n",
      "Result:\n",
      "Hi Clayton, I think they’re looking for someone with at least an analyst profile, though I think they’re very flexible. They may need this to move to a full-time position longer-term.\n"
     ]
    }
   ],
   "source": [
    "for i in bm25.get_top_n(tokenized_query, test_corpus, n=5):\n",
    "    print('Result:')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28633666",
   "metadata": {},
   "source": [
    "We see phone numbers included in the result (none listed in Slack search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a260402",
   "metadata": {},
   "source": [
    "#### Email addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03c202fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"email addresses\"\n",
    "tokenized_query = query.split(\" \")\n",
    "doc_scores = bm25.get_scores(tokenized_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b98c5047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "<@UKJAL3UKB> well if we're putting grievances out there I have one that might be resolved by now. Originally zscalar did not have company specific pools of public IP addresses allocated to the VPN service, this meant we couldn't use the corporate VPN to open up access to a large pool of data because a lot of PII/PHI data in the particular business unit I worked with. I believe there was a release where enterprise companies could pay for their own IP pool in the last year or so.\n",
      "Result:\n",
      "Hi everyone, my friend is an MPH student at Berkeley and asked to share this job opp working on a COVIDScholar tool to contribute to the dissemination of scientific information regarding the pandemic. There is more information on the flyer attached.\n",
      "\n",
      "If you have any questions feel free to shoot an email to <mailto:egainor33@berkeley.edu|egainor33@berkeley.edu>, <mailto:hildy.fong@berkeley.edu|hildy.fong@berkeley.edu> and/or <mailto:jdagdelen@berkeley.edu|jdagdelen@berkeley.edu>.\n",
      "Result:\n",
      "Hi all! My friend’s team is seeking a UX Designer over at Fiat Chrysler Automobiles. If you’re interested, please send your resume and an intro blurb about yourself to Nur at <mailto:nur.icel@fcagroup.com|nur.icel@fcagroup.com>. \n",
      "Result:\n",
      "Glassdoor is looking for a more senior Machine Learning Engineer (2+ years of applying ML in production environments). Feel free to reach out to alum Dan Kent (MIDS '19) at <mailto:dan.kent@glassdoor.com|dan.kent@glassdoor.com> with any questions. <https://boards.greenhouse.io/glassdoor/jobs/5078529002>\n",
      "Result:\n",
      "<@URRQ1E50S> and others --- happy to help put in a good word. My email is <mailto:kwong@cdc.gov|kwong@cdc.gov>.\n"
     ]
    }
   ],
   "source": [
    "for i in bm25.get_top_n(tokenized_query, test_corpus, n=5):\n",
    "    print('Result:')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16546abf",
   "metadata": {},
   "source": [
    "#### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "960b4372",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"dates\"\n",
    "tokenized_query = query.split(\" \")\n",
    "doc_scores = bm25.get_scores(tokenized_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8bdb06e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "I think they hired some last year but more this year.\n",
      "Result:\n",
      "I know, right?! On the other hand, I didn't really think we needed to be in the '90s by the first week in April, so I welcome the variety!\n",
      "Result:\n",
      "I applied for their summer internships this spring 2021. In my past experience, they didn't post intern listings until the early spring before summer. There are no intern positions that I am aware of right now.\n",
      "Result:\n",
      "Not sure how it works in other companies, but we usually get budgets only till the end of the year this early in the year. Probably towards the end of the year, we'd have more clarity on recruiting for next year.\n",
      "Result:\n",
      "<@U1UKGEH4J> how often is this internship offered - is it offered at other times of year or is it summer only? I'm interested, but I'm in my first year of MIDS so I think that it may be helpful to finish the core courses first.\n"
     ]
    }
   ],
   "source": [
    "for i in bm25.get_top_n(tokenized_query, test_corpus, n=5):\n",
    "    print('Result:')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea981c",
   "metadata": {},
   "source": [
    "#### Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc9b5322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "We are location agnostic within the continental US, fully remote is available and we have offices in St. Louis, Chicago, Minneapolis, Dallas, Atlanta, and New Jersey (sort of).\n",
      "Result:\n",
      "Georgia Pacific is hiring Senior Data Scientists! If you are interested in either of these roles, please *email me your resume by Thursday, March 4th* (no cover letter required).\n",
      "\n",
      "Senior Data Scientist – Atlanta, GA\n",
      "<https://referrals.kochcareers.com/jobs/6330678-senior-data-scientist?bid=186&amp;referral=1&amp;internal=1>\n",
      "\n",
      "Sr. Data Scientist - Utility Analytics (Multiple locations):\n",
      "<https://jobs.kochcareers.com/jobs/5953900-sr-data-scientist-utility-analytics>\n",
      "NOTE: locations for this role are -  Santa Clara, California, Tacoma, Washington, Wichita, Kansas, St. Louis, Missouri, Atlanta, Georgia, New York, New York, Tulsa, Oklahoma, Chicago, Illinois, Denver, Colorado\n",
      " \n",
      "*When submitting your resume, please indicate which role you are interested in, and for the Utility Analytics role, also indicate your location preference.*\n",
      "Result:\n",
      "Analysis Group is hiring data scientists in Boston, MA and Montreal, QC, Canada. Description is attached. Links to apply:\n",
      "Boston - <https://professionalcareers-analysisgroup.icims.com/jobs/1784/data-scientist/job>\n",
      "Montreal - <https://professionalcareers-analysisgroup.icims.com/jobs/1785/data-scientist/job>\n",
      "Result:\n",
      "Hey all. Come join me at Govini in Pittsburgh or DC. We are staffing up and hiring for DS, DA, ML, DE, SE etc. Pretty much everything. The roles require that you are a US citizen and can obtain a security clearance (not required to start). Here is a link to the roles. Ping me if you’re interested. <https://jobs.lever.co/govini|https://jobs.lever.co/govini>\n",
      "Result:\n",
      "Oooh, Barcelona...:dancer::dancer::dancer:\n"
     ]
    }
   ],
   "source": [
    "query = \"locations\"\n",
    "tokenized_query = query.split(\" \")\n",
    "doc_scores = bm25.get_scores(tokenized_query)\n",
    "for i in bm25.get_top_n(tokenized_query, test_corpus, n=5):\n",
    "    print('Result:')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b789f",
   "metadata": {},
   "source": [
    "#### Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3c3df26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "Thanks! Will contact tmr morning!\n",
      "Result:\n",
      "Just a reminder to apply by tonight if you're interested in working with the D-Lab! The <https://berkeley.qualtrics.com/jfe/form/SV_bxgWFFHiQy7JZRP|application> should take you 10 minutes or less.\n",
      "Result:\n",
      "Shared via the noise listserve earlier today...\n",
      "<https://megagon.ai/jobs/internships/>\n",
      "Result:\n",
      "From a friend:  Would any of your current/former data science students be interested part time / contractor work few hours a week? Just need to know SQL and possibly some Python, bonus if familiar with Mode. Analyzing teacher/school marketplace data / for my company Swing Education. Data spans product analytics to marketing and ops. Rate is $40-50/hour but negotiable depending on experience and # hours.\n",
      "Result:\n",
      "and we are hiring a data product PM.  your chance to boss me around.\n",
      "or if anyone knows anyone interested …\n",
      "<https://boards.greenhouse.io/voxmedia/jobs/2952098>\n"
     ]
    }
   ],
   "source": [
    "query = \"times\"\n",
    "tokenized_query = query.split(\" \")\n",
    "doc_scores = bm25.get_scores(tokenized_query)\n",
    "for i in bm25.get_top_n(tokenized_query, test_corpus, n=5):\n",
    "    print('Result:')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d9315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
